---
title: "Chapter 4"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.





# Chapter 4. Over-Fitting and Model Tuning 

## 4.1 The problem of over-fitting 

## 4.2 Model tuning 

## 4.3 Data splitting 

```{r}
# Pre-processing the predictor data 
# Estimating model parameters 
# Selecting predictors for the model
# Evaluating model performance 
# Fine tuning class prediction rules (via ROC curves)
```

## 4.4 Resampling techniques 
```{r}
# K-fold cross-validation
# Generalized cross-validation
# Repeated training/test splits 
# The bootstrap
```

## 4.5 Case study: credit scoring

## 4.6 Choosing final tuning parameters 

## 4.7 Data splitting recommendations 
```{r}
# simple 10-fold cross-validation should provide acceptable variance, low bias, and is relatively quick to compute
```

## 4.8 Choosing between models 
```{r}
# 1. Start with several models that are the least interpretable and most flexible, such as boosted trees or support vector machines. Across many problem domains, these models have a high likelihood of producing the empirically optimum results 
# 2. Investigate simpler models that are less opaque(not complete black boxes), such as multivariate adaptive regression splines (MARS), partial least squares, generalized addictive models, or naive bayes models.
# 3. Consider using the simplest model that reasonably approximates the performance of the more complex methods
```

## 4.9 Computing 

```{r}
library(AppliedPredictiveModeling)
library(caret)
# library(Design)
library(e1071)
library(ipred)
library(MASS)
```

### Data Spitting 

```{r}
data(twoClassData)
```

```{r}
str(predictors)
```

```{r}
str(classes)
```

```{r}
set.seed(1)
trainingRows <- createDataPartition(classes, p=.80, list = FALSE)
head(trainingRows)
```

```{r}
trainPredictors <- predictors[trainingRows,]
trainClasses <- classes[trainingRows]
testPredictors <- predictors[-trainingRows,]
testClasses <- classes[-trainingRows]
```

```{r}
str(trainPredictors)
str(testPredictors)
```


### Resampling 
```{r}
set.seed(1)
repeatedSplits <- createDataPartition(trainClasses, p=.80,times=3)
str(repeatedSplits)
```

```{r}
set.seed(1)
cvSplits <- createFolds(trainClasses, k=10, returnTrain = TRUE)
str(cvSplits)
```

```{r}
fold1 <- cvSplits[[1]]
fold1
```

```{r}
cvPredictors1 <- trainPredictors[fold1,]
cvClasses1 <- trainClasses[fold1]
nrow(trainPredictors)
nrow(cvPredictors1)
```


### Basic Model Building in R 
```{r}
# the formula interface
modelFunction(price ~ numBedrooms + numBaths + acres, data = housingData)

# the non-formula interface 
modelFunction(x = housePredictors, y = price)
```

```{r}
# knn3 
trainPredictors <- as.matrix(trainPredictors)
knnFit <- knn3(x = trainPredictors, y = trainClasses, k=5)
knnFit
```

```{r}
testPredictions <- predict(knnFit, newdata = testPredictors, type = "class")
head(testPredictions)
str(testPredictions)
```


### Determination of tuning parameters
```{r}
library(caret)
data(GermanCredit)
```

```{r}
# Data splitting
GermanCredit <- GermanCredit[, -nearZeroVar(GermanCredit)]
GermanCredit$CheckingAccountStatus.lt.0 <- NULL
GermanCredit$SavingsAccountBonds.lt.100 <- NULL
GermanCredit$EmploymentDuration.lt.1 <- NULL
GermanCredit$EmploymentDuration.Unemployed <- NULL
GermanCredit$Personal.Male.Married.Widowed <- NULL
GermanCredit$Property.Unknown <- NULL
GermanCredit$Housing.ForFree <- NULL

set.seed(100)
inTrain <- createDataPartition(GermanCredit$Class, p = .8)[[1]]
GermanCreditTrain <- GermanCredit[ inTrain, ]
GermanCreditTest  <- GermanCredit[-inTrain, ]
```

```{r}
set.seed(1056)
svmFit <- train(Class ~ .,
                data = GermanCreditTrain,
                method = "svmRadial")
```

```{r}
set.seed(1056)
svmFit <- train(Class ~ .,
                data = GermanCreditTrain, 
                method = "svmRadial",
                preProc = c('center','scale'))
```

```{r}
set.seed(1056)
svmFit <- train(Class ~ ., 
                data = GermanCreditTrain,
                method = "svmRadial",
                preProc = c('center','scale'),
                tuneLength = 10)
```

```{r}
set.seed(1056)
svmFit <- train(Class ~ ., 
                data = GermanCreditTrain,
                method = 'svmRadial',
                preProc = c('center','scale'),
                tuneLength = 10,
                trControl = trainControl(method = 'repeatedcv',repeats = 5))
```

```{r}
svmFit
```

```{r}
plot(svmFit)
```

```{r}
plot(svmFit, scales = list(x=list(log = 2)))
```

```{r}
predictedClasses <- predict(svmFit, GermanCreditTest)
str(predictedClasses)
```

```{r}
predictedProbs <- predict(svmFit, newdata = GermanCreditTest, type = "prob")
head(predictedProbs)
```


### Between model comparisons 
```{r}
set.seed(1056)
logisticReg <- train(Class ~ ., 
                     data = GermanCreditTrain,
                     method = "glm",
                     trControl = trainControl(method = "repeatedcv", repeats = 5))
logisticReg
```

```{r}
resamp <- resamples(list(SVM = svmFit, Logistic = logisticReg))
summary(resamp)
```

```{r}
modelDifferences <- diff(resamp)
summary(modelDifferences)
```

